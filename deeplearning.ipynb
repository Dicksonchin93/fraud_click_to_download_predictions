{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f6c832c3-e3b1-455d-bb74-5ff26e17d819",
    "_uuid": "f98c71b9c12134633477169bf8de487bcc98d5cb"
   },
   "source": [
    "In this notebook I continue and improve on the work by Mr. Kireev from his great DL [here](https://www.kaggle.com/alexanderkireev/deep-learning-support-9663). All credit goes to him, I have simply tuned hyperparameters and messed around with the layers of the network (+ some validation).\n",
    "\n",
    "First we will read the data, starting after row 131886954."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcek/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading\n",
      "finished loading\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "\n",
    "dtypes = {\n",
    "        'ip'            : 'uint32',\n",
    "        'app'           : 'uint16',\n",
    "        'device'        : 'uint16',\n",
    "        'os'            : 'uint16',\n",
    "        'channel'       : 'uint16',\n",
    "        'is_attributed' : 'uint8',\n",
    "        'click_id'      : 'uint32'\n",
    "        }\n",
    "\n",
    "print('loading')\n",
    "\n",
    "train_columns = ['ip', 'app', 'device', 'os', 'channel', 'click_time', 'is_attributed']\n",
    "test_columns = ['click_id', 'ip', 'app', 'device', 'os', 'channel', 'click_time']\n",
    "\n",
    "path = ''\n",
    "path_old = 'old/'\n",
    "path_two = \"mnt/ssd/kaggle-talkingdata2/competition_files/\"\n",
    "path_train = path_two + 'train.csv'\n",
    "path_test = path + 'test.csv'\n",
    "path_old_test = path_old + 'old_test.csv'\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(path+\"train.csv\", dtype=dtypes, usecols=train_columns)\n",
    "test_df = pd.read_csv(path_old_test, dtype=dtypes, usecols=test_columns)\n",
    "print('finished loading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>is_attributed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83230</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:32:21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:33:34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35810</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:34:12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45745</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>478</td>\n",
       "      <td>2017-11-06 14:34:52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161007</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:35:08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel           click_time  is_attributed\n",
       "0   83230    3       1  13      379  2017-11-06 14:32:21              0\n",
       "1   17357    3       1  19      379  2017-11-06 14:33:34              0\n",
       "2   35810    3       1  13      379  2017-11-06 14:34:12              0\n",
       "3   45745   14       1  13      478  2017-11-06 14:34:52              0\n",
       "4  161007    3       1  13      379  2017-11-06 14:35:08              0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "25567b128ab04b17307fcac6b8ffb965c16306ea"
   },
   "source": [
    "The preprocessing is the same as the [original kernel](https://www.kaggle.com/alexanderkireev/deep-learning-support-9663)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "c1ce582d-c8b0-4740-8dc0-f4300b63d04d",
    "_uuid": "07bcf27d2da01c7a30a5c53eecbfe20dc4bd0925"
   },
   "outputs": [],
   "source": [
    "def prep_data(d):\n",
    "    print('hour, day, wday....')\n",
    "    d['hour'] = pd.to_datetime(d.click_time).dt.hour.astype('uint8')\n",
    "    d['day'] = pd.to_datetime(d.click_time).dt.day.astype('uint8')\n",
    "    d['wday']  = pd.to_datetime(d.click_time).dt.dayofweek.astype('uint8')\n",
    "    print('grouping by ip-day-hour combination....')\n",
    "    gp = d[['ip', 'day', 'hour', 'channel']].groupby(by=['ip', 'day', 'hour'])[['channel']].count().reset_index().rename(index=str, columns={'channel': 'qty'})\n",
    "    d = d.merge(gp, on=['ip', 'day', 'hour'], how='left')\n",
    "    del gp; gc.collect()\n",
    "    print('group by ip-app combination....')\n",
    "    gp = d[['ip', 'app', 'channel']].groupby(by=['ip', 'app'])[['channel']].count().reset_index().rename(index=str, columns={'channel': 'ip_app_count'})\n",
    "    d = d.merge(gp, on=['ip', 'app'], how='left')\n",
    "    del gp; gc.collect()\n",
    "    print('group by ip-app-os combination....')\n",
    "    gp = d[['ip', 'app', 'os', 'channel']].groupby(by=['ip', 'app', 'os'])[['channel']].count().reset_index().rename(index=str, columns={'channel': 'ip_app_os_count'})\n",
    "    d = d.merge(gp, on=['ip', 'app', 'os'], how='left')\n",
    "    del gp; gc.collect()\n",
    "    print(\"vars and d type....\")\n",
    "    d['qty'] = d['qty'].astype('uint16')\n",
    "    d['ip_app_count'] = d['ip_app_count'].astype('uint16')\n",
    "    d['ip_app_os_count'] = d['ip_app_os_count'].astype('uint16')\n",
    "    print(\"label encoding....\")\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    d[['app', 'device', 'os', 'channel', 'hour', 'day', 'wday']].apply(LabelEncoder().fit_transform)\n",
    "    print('dropping')\n",
    "    #d.drop(['click_time', 'ip'], 1, inplace=True)\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "63aae1c3-920f-4fa6-a481-e0d60ee1c21c",
    "_uuid": "272772bf7040b4c4f12942bbc0b824c6a6862a7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hour, day, wday....\n",
      "grouping by ip-day-hour combination....\n",
      "group by ip-app combination....\n",
      "group by ip-app-os combination....\n",
      "vars and d type....\n",
      "label encoding....\n",
      "dropping\n",
      "hour, day, wday....\n",
      "grouping by ip-day-hour combination....\n",
      "group by ip-app combination....\n",
      "group by ip-app-os combination....\n",
      "vars and d type....\n",
      "label encoding....\n",
      "dropping\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "train_df = prep_data(train_df)\n",
    "test_df = prep_data(test_df)\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b872e056-9933-4a31-827b-ce7f9d7d44c6",
    "_uuid": "99e0a55d2b29714f0d95c14dba6d779a840b449b"
   },
   "source": [
    "We will keep 10% of the training dataset for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the validation set is  37170060\n",
      "The size of the train set is  144708152\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from datetime import datetime\n",
    "VALIDATE = True\n",
    "RANDOM_SEED = 1\n",
    "import random\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "#predictors =  ['app','channel','click_time', 'device','ip','is_attributed', 'os', 'hour', 'day','ip_app_channel_var_day', 'n_channels', 'ip_app_count', 'ip_app_os_count', 'qty_var','ip_app_os_var','ip_app_channel_mean_hour','ip_nextClick','ip_app_nextClick','ip_channel_nextClick','ip_os_nextClick','clicks_by_ip','nip_hh_os','nip_hh_app','nip_hh_dev', 'prev_app_clicks','future_app_clicks','prev_identical_clicks','future_identical_clicks','nip_day_test_hh','ip_prevClick','ip_app_prevClick']\n",
    "if VALIDATE:\n",
    "    train_df['click_time']= pd.to_datetime(train_df['click_time'])\n",
    "    start_date = datetime(2017,11,9,4,0,0)\n",
    "    end_date = datetime(2017,11,9,15,0,0)\n",
    "    maskval = (train_df['click_time'] >= start_date) & (train_df['click_time'] <= end_date)\n",
    "    masktrain = (train_df['click_time'] < start_date)\n",
    "    \n",
    "    r = 0.1 # the fraction of the train data to be used for validation\n",
    "    #val = train[(len_train-round(r*len_train)):len_train]\n",
    "    X_test = train_df.loc[maskval]\n",
    "    print('The size of the validation set is ', len(X_test))\n",
    "    \n",
    "    #train = train[:(len_train-round(r*len_train))]\n",
    "    X_train = train_df.loc[masktrain]\n",
    "    print('The size of the train set is ', len(X_train))\n",
    "    \n",
    "    y_train = X_train['is_attributed']\n",
    "    X_train = X_train.drop(['is_attributed'], axis=1)\n",
    "    y_test = X_test['is_attributed']\n",
    "    X_test = X_test.drop(['is_attributed'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "8348140a-05a6-4adf-b72a-bcaaed4012f5",
    "_uuid": "dd687254fa92eb3aa164bb1cae8c98f737d25314"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, Dense, Flatten, Dropout, concatenate\n",
    "from keras.layers import BatchNormalization, SpatialDropout1D, Conv1D\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "fc14f366-6fdc-4650-9963-db9ebce4ed73",
    "_uuid": "bd3fdea9fe0e013f16dd9105d4d427c30ed80258"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>wday</th>\n",
       "      <th>qty</th>\n",
       "      <th>ip_app_count</th>\n",
       "      <th>ip_app_os_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83230</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:32:21</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5427</td>\n",
       "      <td>1326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:33:34</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5025</td>\n",
       "      <td>1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35810</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:34:12</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45745</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>478</td>\n",
       "      <td>2017-11-06 14:34:52</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9474</td>\n",
       "      <td>1954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161007</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:35:08</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>232</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel          click_time  hour  day  wday  qty  \\\n",
       "0   83230    3       1  13      379 2017-11-06 14:32:21    14    6     0    1   \n",
       "1   17357    3       1  19      379 2017-11-06 14:33:34    14    6     0    1   \n",
       "2   35810    3       1  13      379 2017-11-06 14:34:12    14    6     0    1   \n",
       "3   45745   14       1  13      478 2017-11-06 14:34:52    14    6     0    1   \n",
       "4  161007    3       1  13      379 2017-11-06 14:35:08    14    6     0    1   \n",
       "\n",
       "   ip_app_count  ip_app_os_count  \n",
       "0          5427             1326  \n",
       "1          5025             1380  \n",
       "2          2012              442  \n",
       "3          9474             1954  \n",
       "4           232               80  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "94c22103-510a-4da6-bce9-94d532c10bcf",
    "_uuid": "813eca588b6fb58312513855742a52ae0a68b74d"
   },
   "outputs": [],
   "source": [
    "def get_keras_data(dataset):\n",
    "    X = {\n",
    "        'app': np.array(dataset.app),\n",
    "        'ch': np.array(dataset.channel),\n",
    "        'dev': np.array(dataset.device),\n",
    "        'os': np.array(dataset.os),\n",
    "        'h': np.array(dataset.hour),\n",
    "        'd': np.array(dataset.day),\n",
    "        'wd': np.array(dataset.wday),\n",
    "        'qty': np.array(dataset.qty),\n",
    "        'c1': np.array(dataset.ip_app_count),\n",
    "        'c2': np.array(dataset.ip_app_os_count)\n",
    "    }\n",
    "    return X\n",
    "\n",
    "train = get_keras_data(X_train)\n",
    "test = get_keras_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "8f2db467-84c6-495a-9ae5-d0b73f06e106",
    "_uuid": "4deb2b4ba4553e582f44a31ee18c689427368c36"
   },
   "outputs": [],
   "source": [
    "max_app = np.max([train_df['app'].max(), test_df['app'].max()])+1\n",
    "max_ch = np.max([train_df['channel'].max(), test_df['channel'].max()])+1\n",
    "max_dev = np.max([train_df['device'].max(), test_df['device'].max()])+1\n",
    "max_os = np.max([train_df['os'].max(), test_df['os'].max()])+1\n",
    "max_h = np.max([train_df['hour'].max(), test_df['hour'].max()])+1\n",
    "max_d = np.max([train_df['day'].max(), test_df['day'].max()])+1\n",
    "max_wd = np.max([train_df['wday'].max(), test_df['wday'].max()])+1\n",
    "max_qty = np.max([train_df['qty'].max(), test_df['qty'].max()])+1\n",
    "max_c1 = np.max([train_df['ip_app_count'].max(), test_df['ip_app_count'].max()])+1\n",
    "max_c2 = np.max([train_df['ip_app_os_count'].max(), test_df['ip_app_os_count'].max()])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "4a6d042c-be87-418f-b617-b87f38a90aa5",
    "_uuid": "def5b2fc34cae09852c26f1f694a6e22bdb33e4c"
   },
   "outputs": [],
   "source": [
    "emb_n = 50\n",
    "\n",
    "in_app = Input(shape=[1], name = 'app')\n",
    "emb_app = Embedding(max_app, emb_n)(in_app)\n",
    "in_ch = Input(shape=[1], name = 'ch')\n",
    "emb_ch = Embedding(max_ch, emb_n)(in_ch)\n",
    "in_dev = Input(shape=[1], name = 'dev')\n",
    "emb_dev = Embedding(max_dev, emb_n)(in_dev)\n",
    "in_os = Input(shape=[1], name = 'os')\n",
    "emb_os = Embedding(max_os, emb_n)(in_os)\n",
    "in_h = Input(shape=[1], name = 'h')\n",
    "emb_h = Embedding(max_h, emb_n)(in_h) \n",
    "in_d = Input(shape=[1], name = 'd')\n",
    "emb_d = Embedding(max_d, emb_n)(in_d) \n",
    "in_wd = Input(shape=[1], name = 'wd')\n",
    "emb_wd = Embedding(max_wd, emb_n)(in_wd) \n",
    "in_qty = Input(shape=[1], name = 'qty')\n",
    "emb_qty = Embedding(max_qty, emb_n)(in_qty) \n",
    "in_c1 = Input(shape=[1], name = 'c1')\n",
    "emb_c1 = Embedding(max_c1, emb_n)(in_c1) \n",
    "in_c2 = Input(shape=[1], name = 'c2')\n",
    "emb_c2 = Embedding(max_c2, emb_n)(in_c2) \n",
    "fe = concatenate([(emb_app), (emb_ch), (emb_dev), (emb_os), (emb_h), \n",
    "                 (emb_d), (emb_wd), (emb_qty), (emb_c1), (emb_c2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c29dff1a-79c2-40bc-b425-6d6e036ea9b1",
    "_uuid": "1027f33e1aaa320c3f72cf5cb2f2e4cb0a1bc255"
   },
   "source": [
    "Below we will build the main core of the network. If you want to mess around, I suggest you start by adjusting the `Dropout` parameters. I have noticed that up to 0.5 it works really well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "f86e3fc1-d6c3-43dc-9859-a20eefe8d75e",
    "_uuid": "5809695337539ae5103be1e53a92f1a15cd123e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dcek/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    }
   ],
   "source": [
    "s_dout = SpatialDropout1D(0.25)(fe)\n",
    "\n",
    "fl1 = Flatten()(s_dout)\n",
    "conv1 = Conv1D(70, kernel_size=2, strides=1, padding='same')(s_dout)\n",
    "fl2 = Flatten()(conv1)\n",
    "conv2 = Conv1D(70, kernel_size=4, strides=1, padding='same')(s_dout)\n",
    "fl3 = Flatten()(conv2)\n",
    "\n",
    "concat = concatenate([(fl1), (fl2), (fl3)])\n",
    "\n",
    "x = Dropout(0.2)(Dense(500, activation='relu')(concat))\n",
    "x = Dropout(0.3)(Dense(750, activation='relu')(x))\n",
    "x = Dropout(0.4)(Dense(1000, activation='relu')(x))\n",
    "outp = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=[in_app,in_ch,in_dev,in_os,in_h,in_d,in_wd,in_qty,in_c1,in_c2], outputs=outp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ff7ee343-f95d-4192-88ca-d9df90915800",
    "_uuid": "cae8e7df9d43cb90b6873e8babd274deb96a9065"
   },
   "source": [
    "Time to train our network!\n",
    "\n",
    "Possible improvements include increasing `batch_size` and the adjusting the `lr_decay` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "7ada4048-e658-4e39-8bec-9e811f89eafc",
    "_uuid": "b0b087386ae755bd94162b8711bb0a46e2ea263f"
   },
   "outputs": [],
   "source": [
    "batch_size = 25000\n",
    "epochs = 1\n",
    "exp_decay = lambda init, fin, steps: (init/fin)**(1/(steps-1)) - 1\n",
    "steps = int(len(train_df) / batch_size) * epochs\n",
    "lr_init, lr_fin = 0.0025, 0.0001\n",
    "lr_decay = exp_decay(lr_init, lr_fin, steps)\n",
    "optimizer_adam = Adam(lr=0.0025, decay=lr_decay)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer_adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "epochs =10\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=5, \\\n",
    "                          verbose=1, mode='auto')\n",
    "callbacks_list = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "2b637a71-7f81-40f5-b464-23ff1be1c9d9",
    "_uuid": "8b5ed06eb8d44ac31bab54954ce6e7336b26f06e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Train on 144708152 samples, validate on 37170060 samples\n",
      "Epoch 1/10\n",
      "144708152/144708152 [==============================] - 741s 5us/step - loss: 0.0016 - acc: 0.9875 - val_loss: 0.0771 - val_acc: 0.9843\n",
      "Epoch 2/10\n",
      "144708152/144708152 [==============================] - 730s 5us/step - loss: 0.0015 - acc: 0.9880 - val_loss: 0.0748 - val_acc: 0.9845\n",
      "Epoch 3/10\n",
      "144708152/144708152 [==============================] - 733s 5us/step - loss: 0.0015 - acc: 0.9881 - val_loss: 0.0652 - val_acc: 0.9840\n",
      "Epoch 4/10\n",
      "144708152/144708152 [==============================] - 734s 5us/step - loss: 0.0014 - acc: 0.9881 - val_loss: 0.0671 - val_acc: 0.9832\n",
      "Epoch 5/10\n",
      "144708152/144708152 [==============================] - 730s 5us/step - loss: 0.0014 - acc: 0.9881 - val_loss: 0.0731 - val_acc: 0.9825\n",
      "Epoch 6/10\n",
      "  1250000/144708152 [..............................] - ETA: 25:58 - loss: 0.0014 - acc: 0.9880"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-600915391a78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m.99\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m# magic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class_weight = {0:.01,1:.99} # magic\n",
    "model.fit(train, y_train, batch_size=batch_size, epochs=epochs, class_weight=class_weight, validation_data=(test, y_test),callbacks=callbacks_list, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(model_history):\n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
    "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = get_keras_data(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "b87cb312-67d2-473d-8481-79a88d18bb1d",
    "_uuid": "c70234f84a09238047d87340d00aa071a489bc08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57537505/57537505 [==============================] - 111s 2us/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(test_df, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = ''\n",
    "path_old = 'old/'\n",
    "path_two = \"mnt/ssd/kaggle-talkingdata2/competition_files/\"\n",
    "path_train = path + 'train.csv'\n",
    "path_test = path + 'test.csv'\n",
    "path_old_test = path_old + 'old_test.csv'\n",
    "\n",
    "hello = pd.read_csv(path_test, dtype='int', usecols=['click_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pd.read_csv('mapping.csv', dtype={'click_id': 'int32','old_click_id': 'int32'}, engine='c',\n",
    "                na_filter=False,memory_map=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15868"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting the submission data...\n"
     ]
    }
   ],
   "source": [
    "submit = pd.read_csv(path_old_test, dtype='int', usecols=['click_id'])\n",
    "\n",
    "print(\"Predicting the submission data...\")\n",
    "\n",
    "submit['is_attributed'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = pd.merge(hello, mapping, on='click_id')\n",
    "final_pred = final_pred.rename(columns={'click_id':'temp', 'old_click_id': 'click_id'})\n",
    "final_pred_final = pd.merge(final_pred, submit, on='click_id')\n",
    "final_pred_final.drop('click_id', axis=1, inplace=True )\n",
    "final_pred_final = final_pred_final.rename(columns={'temp':'click_id'})\n",
    "final_pred_final.to_csv('predict_feature.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b92df68b-28d4-49a8-a86d-a3f59f62fee6",
    "_uuid": "40e405b3f6d5672983fa03bc3b1a33637d078ff7"
   },
   "source": [
    "## Validation\n",
    "\n",
    "Here we will perform some basic validation on 10% of the collected training data set. We will calculate the ROC-AUC score, from this script [here](https://www.kaggle.com/antmarakis/calculating-and-plotting-auc-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4f62ec99-9f6a-4920-94c8-b0b4493e0d51",
    "_uuid": "783c77b1b49a56ed56365f984f19e213c7d6a11d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,\n",
    "                             roc_curve, recall_score, classification_report, f1_score,\n",
    "                             precision_recall_fscore_support)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, label='AUC = %0.4f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.001, 1])\n",
    "plt.ylim([0, 1.001])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b743923e-6618-4bb7-9baf-3ab6f8e0850e",
    "_uuid": "4e9290b1c37fd37e94f2b280ca12fdfcbadb5ac6"
   },
   "source": [
    "## Submission\n",
    "\n",
    "Finally, creating the submission file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fb5dc002-eaff-4bd0-8442-c81cd14e7d2a",
    "_uuid": "f409d871bc4238f01c173d1eccc5c9e3c7ec951b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = test_df['click_id']\n",
    "test_df.drop('click_id', axis=1, inplace=True)\n",
    "t = get_keras_data(test_df)\n",
    "sub_preds = model.predict(t, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "724a4189-d014-425b-b038-c5607cc308da",
    "_uuid": "987913094f3ee0313facde2cc2aeb514995781e6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['click_id'] = ids\n",
    "sub['is_attributed'] = sub_preds\n",
    "sub.to_csv('dl_sub.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
